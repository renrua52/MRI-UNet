{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = \"./lgg-mri-segmentation/kaggle_3m/\"\n",
    "dirs = []\n",
    "images = []\n",
    "masks = []\n",
    "for dirpath, dirnames, filenames in os.walk(DataPath):\n",
    "    for filename in filenames:\n",
    "        if 'mask' in filename:\n",
    "            dirs.append(dirpath.replace(DataPath, ''))\n",
    "            masks.append(filename)\n",
    "            images.append(filename.replace('_mask', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(idx):\n",
    "    imagePath = os.path.join(DataPath, dirs[idx], images[idx])\n",
    "    maskPath = os.path.join(DataPath, dirs[idx], masks[idx])\n",
    "    image = plt.imread(imagePath)\n",
    "    mask = plt.imread(maskPath)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=[13, 15])\n",
    "    \n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title('Brain MRI')\n",
    "    \n",
    "    axs[1].imshow(mask, cmap='gray')\n",
    "    axs[1].set_title('Mask')\n",
    "    \n",
    "    axs[2].imshow(image)\n",
    "    axs[2].imshow(mask, cmap='gray', alpha=0.3)\n",
    "    axs[2].set_title('MRI with mask')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "for idx in range(5):\n",
    "    plot_image(idx+100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.dirs = dirs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imagePath = os.path.join(DataPath, dirs[idx], images[idx])\n",
    "        maskPath = os.path.join(DataPath, dirs[idx], masks[idx])\n",
    "\n",
    "        image = plt.imread(imagePath)/255\n",
    "        image = torch.from_numpy(image).type(torch.float32)\n",
    "        image = image.permute((2, 0, 1))\n",
    "\n",
    "        mask = np.expand_dims(plt.imread(maskPath)/255, axis=-1)\n",
    "        mask = torch.from_numpy(mask).type(torch.float32)\n",
    "        mask = mask.permute((2, 0, 1))\n",
    "        return image, mask\n",
    "    \n",
    "dataset = MRIDataset()\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(images) - train_size\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Contract(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.doubleConv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.doubleConv(x)\n",
    "        return x\n",
    "    \n",
    "class Expand(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
    "        self.doubleConv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, shortcut):\n",
    "        x = self.upsample(x)\n",
    "        return self.doubleConv(torch.cat([shortcut, x], dim=1))\n",
    "    \n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.inconv = DoubleConv(3, 64)\n",
    "        self.down1 = Contract(64, 128)\n",
    "        self.down2 = Contract(128, 256)\n",
    "        self.down3 = Contract(256, 512)\n",
    "        self.down4 = Contract(512, 1024)\n",
    "        self.up1 = Expand(1024, 512)\n",
    "        self.up2 = Expand(512, 256)        \n",
    "        self.up3 = Expand(256, 128)        \n",
    "        self.up4 = Expand(128, 64)\n",
    "        self.outconv = OutConv(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inconv(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        return self.outconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(pred, label):\n",
    "    intersection = 2.0 * (pred * label).sum()\n",
    "    union = pred.sum() + label.sum()\n",
    "    if union == 0:\n",
    "        return 1\n",
    "    return intersection/union\n",
    "\n",
    "def dice_loss(pred, label):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * (pred * label).sum() + smooth\n",
    "    union = pred.sum() + label.sum() + smooth\n",
    "    return 1 - (intersection/union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.randn(4, 3, 256, 256).to(device))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_set = []\n",
    "accu_set = []\n",
    "disp_freq = 100\n",
    "iter_per_batch = train_size//batch_size\n",
    "\n",
    "model.train()\n",
    "for epoch in range(max_epoch):\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = dice_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_set.append(loss.item())\n",
    "\n",
    "        out_cut = np.copy(output.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "        accuracy = dice_metric(output, target)\n",
    "        accu_set.append(accuracy)\n",
    "\n",
    "        if batch_id % disp_freq == 0:\n",
    "            print(\"Epoch [{}][{}]\\t Batch [{}][{}]\\t Training Loss {:.4f}\\t Accuracy {:.4f}\".format(\n",
    "                epoch, max_epoch, batch_id, iter_per_batch, \n",
    "                loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
